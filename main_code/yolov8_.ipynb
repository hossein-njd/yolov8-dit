{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### codes that need befor main codig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/ultralytics.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {ROOT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naw we start conding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image as imgshow\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we start whit Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=yolov8n.pt conf=0.7 source=\"input/dogs_n_cars.jpg\" save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgshow(os.path.join(ROOT_DIR,\"runs/detect/predict3/dogs_n_cars.jpg\"), width = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source=\"input/test_vid.mp4\" save=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other way to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#import requests\n",
    "#from io import BytesIO\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open('dogs_n_cars.jpg')\n",
    "# image = np.asarray(image)\n",
    "# results = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_bboxes(image, results[0].boxes.boxes, score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=predict model='yolov8n-seg.pt' conf=0.25 source=\"dogs_n_cars.jpg\" save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgshow(os.path.join(ROOT_DIR,'/runs/segment/predict3/dogs_n_cars.jpg'), width = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=predict conf=0.25 source=\"input/test_vid.mp4\" save=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.19)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (10.0.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\amir\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\amir\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: supervision in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (0.18.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.0.6)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\amir\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amir\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->roboflow) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->roboflow) (3.3.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supervision->roboflow) (0.7.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supervision->roboflow) (1.11.4)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.15, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Football-Player-Detection-3 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49043/49043 [01:58<00:00, 415.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Football-Player-Detection-3 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3402/3402 [00:01<00:00, 2211.99it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"iPbN0pELs0crUvSHfZRv\")\n",
    "project = rf.workspace(\"bronkscottema\").project(\"football-player-detection\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e:\\\\work\\\\github\\\\first-project\\\\main_code\\\\ultralytics\\\\ultralytics\\\\ultralytics\\\\Football-Player-Detection-3'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{dataset.location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "New https://pypi.org/project/ultralytics/8.2.17 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.15 üöÄ Python-3.11.9 torch-2.2.0+cpu CPU (12th Gen Intel Core(TM) i7-12700H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=e:\\work\\github\\first-project\\main_code\\ultralytics\\ultralytics\\ultralytics\\Football-Player-Detection-3/data.yaml, epochs=20, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/21.5M [00:00<?, ?B/s]\n",
      "  0%|          | 24.0k/21.5M [00:00<01:42, 219kB/s]\n",
      "  0%|          | 56.0k/21.5M [00:00<02:18, 163kB/s]\n",
      "  0%|          | 80.0k/21.5M [00:00<02:30, 150kB/s]\n",
      "  1%|          | 208k/21.5M [00:00<00:52, 430kB/s] \n",
      "  1%|‚ñè         | 304k/21.5M [00:00<00:38, 572kB/s]\n",
      "  2%|‚ñè         | 432k/21.5M [00:00<00:37, 587kB/s]\n",
      "  3%|‚ñé         | 576k/21.5M [00:01<00:28, 777kB/s]\n",
      "  3%|‚ñé         | 688k/21.5M [00:01<00:25, 848kB/s]\n",
      "  4%|‚ñç         | 928k/21.5M [00:01<00:17, 1.26MB/s]\n",
      "  5%|‚ñå         | 1.08M/21.5M [00:01<00:15, 1.38MB/s]\n",
      "  7%|‚ñã         | 1.53M/21.5M [00:01<00:11, 1.83MB/s]\n",
      "  8%|‚ñä         | 1.70M/21.5M [00:01<00:12, 1.68MB/s]\n",
      "  9%|‚ñâ         | 1.94M/21.5M [00:01<00:11, 1.84MB/s]\n",
      " 12%|‚ñà‚ñè        | 2.56M/21.5M [00:01<00:06, 2.95MB/s]\n",
      " 14%|‚ñà‚ñç        | 2.97M/21.5M [00:02<00:05, 3.29MB/s]\n",
      " 16%|‚ñà‚ñå        | 3.39M/21.5M [00:02<00:05, 3.49MB/s]\n",
      " 17%|‚ñà‚ñã        | 3.74M/21.5M [00:02<00:07, 2.51MB/s]\n",
      " 20%|‚ñà‚ñà        | 4.41M/21.5M [00:02<00:05, 3.46MB/s]\n",
      " 24%|‚ñà‚ñà‚ñé       | 5.08M/21.5M [00:02<00:04, 4.28MB/s]\n",
      " 26%|‚ñà‚ñà‚ñå       | 5.60M/21.5M [00:02<00:03, 4.58MB/s]\n",
      " 29%|‚ñà‚ñà‚ñâ       | 6.20M/21.5M [00:02<00:03, 5.01MB/s]\n",
      " 31%|‚ñà‚ñà‚ñà       | 6.73M/21.5M [00:02<00:03, 5.13MB/s]\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 7.39M/21.5M [00:03<00:02, 5.64MB/s]\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 7.95M/21.5M [00:03<00:02, 5.03MB/s]\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 8.89M/21.5M [00:03<00:02, 5.59MB/s]\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 9.86M/21.5M [00:03<00:01, 6.48MB/s]\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 10.5M/21.5M [00:03<00:01, 6.22MB/s]\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 11.2M/21.5M [00:03<00:01, 6.55MB/s]\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 12.0M/21.5M [00:03<00:01, 6.90MB/s]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 12.9M/21.5M [00:03<00:01, 7.62MB/s]\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 13.7M/21.5M [00:03<00:01, 7.52MB/s]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 14.4M/21.5M [00:04<00:01, 7.42MB/s]\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 15.4M/21.5M [00:04<00:00, 8.24MB/s]\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 16.2M/21.5M [00:04<00:00, 7.45MB/s]\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 17.4M/21.5M [00:04<00:00, 8.79MB/s]\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 18.3M/21.5M [00:04<00:00, 8.19MB/s]\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 19.4M/21.5M [00:04<00:00, 9.14MB/s]\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 20.3M/21.5M [00:04<00:00, 9.14MB/s]\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 21.2M/21.5M [00:04<00:00, 8.68MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.5M/21.5M [00:04<00:00, 4.63MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 133, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 327, in check_det_dataset\n",
      "    raise FileNotFoundError(m)\n",
      "FileNotFoundError: \n",
      "Dataset 'e://work/github/first-project/main_code/ultralytics/ultralytics/ultralytics/Football-Player-Detection-3/data.yaml' images not found ‚ö†Ô∏è, missing path 'E:\\work\\github\\first-project\\main_code\\ultralytics\\ultralytics\\ultralytics\\Football-Player-Detection-3\\Football-Player-Detection-3\\valid\\images'\n",
      "Note dataset download directory is 'E:\\work\\github\\first-project\\main_code\\datasets'. You can update this in 'C:\\Users\\Amir\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 568, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 582, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 137, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}\")) from e\n",
      "RuntimeError: Dataset 'e://work/github/first-project/main_code/ultralytics/ultralytics/ultralytics/Football-Player-Detection-3/data.yaml' error  \n",
      "Dataset 'e://work/github/first-project/main_code/ultralytics/ultralytics/ultralytics/Football-Player-Detection-3/data.yaml' images not found , missing path 'E:\\work\\github\\first-project\\main_code\\ultralytics\\ultralytics\\ultralytics\\Football-Player-Detection-3\\Football-Player-Detection-3\\valid\\images'\n",
      "Note dataset download directory is 'E:\\work\\github\\first-project\\main_code\\datasets'. You can update this in 'C:\\Users\\Amir\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=20 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 541, in entrypoint\n",
      "    model = YOLO(model, task=task)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py\", line 23, in __init__\n",
      "    super().__init__(model=model, task=task, verbose=verbose)\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 134, in __init__\n",
      "    self._load(model, task=task)\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 215, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 780, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 708, in torch_safe_load\n",
      "    ckpt = torch.load(file, map_location=\"cpu\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 998, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 445, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 426, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '{ROOT_DIR}\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model={ROOT_DIR}/runs/detect/train3/weights/best.pt data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 541, in entrypoint\n",
      "    model = YOLO(model, task=task)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py\", line 23, in __init__\n",
      "    super().__init__(model=model, task=task, verbose=verbose)\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 134, in __init__\n",
      "    self._load(model, task=task)\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 215, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 780, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 708, in torch_safe_load\n",
      "    ckpt = torch.load(file, map_location=\"cpu\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 998, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 445, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Amir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 426, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '{ROOT_DIR}\\\\runs\\\\detect\\\\train3\\\\weights\\\\best.pt'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model={ROOT_DIR}/runs/detect/train3/weights/best.pt conf=0.25 source={dataset.location}/test/images\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.17 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.15 üöÄ Python-3.11.9 torch-2.2.0+cpu CPU (12th Gen Intel Core(TM) i7-12700H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "\n",
      "Dataset 'coco128.yaml' images not found ‚ö†Ô∏è, missing path 'E:\\work\\github\\first-project\\main_code\\datasets\\coco128\\images\\train2017'\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to 'E:\\work\\github\\first-project\\main_code\\datasets\\coco128.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.66M/6.66M [00:03<00:00, 1.81MB/s]\n",
      "Unzipping E:\\work\\github\\first-project\\main_code\\datasets\\coco128.zip to E:\\work\\github\\first-project\\main_code\\datasets\\coco128...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 263/263 [00:00<00:00, 2810.42file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (18.3s), saved to \u001b[1mE:\\work\\github\\first-project\\main_code\\datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Amir\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:01<00:00, 657kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\work\\github\\first-project\\main_code\\datasets\\coco128\\labels\\train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 786.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\work\\github\\first-project\\main_code\\datasets\\coco128\\labels\\train2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\work\\github\\first-project\\main_code\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.096      1.365      1.202        201        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:20<00:00,  2.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:07<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.647      0.518      0.595      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.216      1.443      1.268        136        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:31<00:00,  3.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:14<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929       0.66      0.542      0.614      0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.193      1.342      1.243        206        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:24<00:00,  3.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:08<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.664      0.548      0.624      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.15 üöÄ Python-3.11.9 torch-2.2.0+cpu CPU (12th Gen Intel Core(TM) i7-12700H)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.664      0.548      0.623      0.463\n",
      "                person        128        254      0.796      0.669      0.762      0.546\n",
      "               bicycle        128          6      0.613      0.333      0.321      0.279\n",
      "                   car        128         46      0.701      0.217      0.278      0.171\n",
      "            motorcycle        128          5      0.675      0.834      0.938      0.764\n",
      "              airplane        128          6      0.749      0.667      0.846      0.588\n",
      "                   bus        128          7      0.529      0.645      0.657      0.595\n",
      "                 train        128          3      0.538      0.667      0.806      0.698\n",
      "                 truck        128         12      0.904      0.333      0.485      0.296\n",
      "                  boat        128          6      0.299      0.167      0.379      0.242\n",
      "         traffic light        128         14      0.691      0.214      0.206       0.14\n",
      "             stop sign        128          2          1       0.94      0.995      0.703\n",
      "                 bench        128          9      0.782      0.404      0.623      0.387\n",
      "                  bird        128         16      0.917       0.69      0.902      0.539\n",
      "                   cat        128          4      0.861          1      0.995       0.82\n",
      "                   dog        128          9      0.724      0.876      0.851      0.619\n",
      "                 horse        128          2      0.563          1      0.995      0.597\n",
      "              elephant        128         17      0.955      0.824      0.896      0.701\n",
      "                  bear        128          1      0.642          1      0.995      0.895\n",
      "                 zebra        128          4      0.861          1      0.995      0.965\n",
      "               giraffe        128          9      0.757      0.889      0.961      0.713\n",
      "              backpack        128          6      0.592      0.333      0.394      0.263\n",
      "              umbrella        128         18      0.743        0.5      0.686      0.453\n",
      "               handbag        128         19      0.466      0.049      0.158     0.0892\n",
      "                   tie        128          7      0.829      0.696      0.702      0.492\n",
      "              suitcase        128          4      0.559          1      0.895      0.621\n",
      "               frisbee        128          5      0.605        0.8      0.733       0.64\n",
      "                  skis        128          1      0.452          1      0.497      0.211\n",
      "             snowboard        128          7      0.779      0.714      0.762      0.489\n",
      "           sports ball        128          6      0.735       0.47      0.573      0.322\n",
      "                  kite        128         10      0.815      0.446      0.558      0.173\n",
      "          baseball bat        128          4      0.487        0.5      0.528      0.228\n",
      "        baseball glove        128          7      0.656      0.429      0.429      0.294\n",
      "            skateboard        128          5      0.786        0.6        0.6      0.426\n",
      "         tennis racket        128          7       0.62      0.286      0.427      0.305\n",
      "                bottle        128         18      0.472      0.333      0.399      0.234\n",
      "            wine glass        128         16      0.683      0.375      0.589      0.352\n",
      "                   cup        128         36      0.745      0.278      0.431      0.297\n",
      "                  fork        128          6          1      0.298      0.372      0.239\n",
      "                 knife        128         16      0.614      0.562      0.595      0.345\n",
      "                 spoon        128         22      0.693      0.182      0.359      0.194\n",
      "                  bowl        128         28      0.655      0.643      0.633      0.531\n",
      "                banana        128          1     0.0629      0.315      0.199     0.0505\n",
      "              sandwich        128          2      0.393       0.68      0.745      0.745\n",
      "                orange        128          4          1      0.415      0.995       0.67\n",
      "              broccoli        128         11      0.529      0.182      0.261      0.229\n",
      "                carrot        128         24      0.632      0.458      0.658      0.406\n",
      "               hot dog        128          2      0.556          1      0.828      0.795\n",
      "                 pizza        128          5      0.663          1      0.995      0.866\n",
      "                 donut        128         14      0.614          1      0.894      0.817\n",
      "                  cake        128          4      0.757          1      0.995      0.834\n",
      "                 chair        128         35      0.472      0.514      0.436      0.263\n",
      "                 couch        128          6      0.741      0.482      0.663      0.533\n",
      "          potted plant        128         14      0.565      0.571      0.672      0.468\n",
      "                   bed        128          3      0.949      0.667       0.83      0.665\n",
      "          dining table        128         13      0.614      0.612      0.545      0.446\n",
      "                toilet        128          2      0.644        0.5      0.828      0.796\n",
      "                    tv        128          2      0.538        0.5      0.662      0.629\n",
      "                laptop        128          3          1          0      0.544      0.426\n",
      "                 mouse        128          2          1          0     0.0298    0.00298\n",
      "                remote        128          8       0.75        0.5      0.573       0.48\n",
      "            cell phone        128          8          0          0     0.0418     0.0209\n",
      "             microwave        128          3      0.497          1      0.863      0.736\n",
      "                  oven        128          5      0.366        0.4      0.374      0.292\n",
      "                  sink        128          6      0.347      0.167      0.267      0.183\n",
      "          refrigerator        128          5      0.541        0.4      0.616       0.49\n",
      "                  book        128         29      0.566      0.103      0.269      0.141\n",
      "                 clock        128          9       0.78      0.791      0.897      0.738\n",
      "                  vase        128          2      0.445          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.199     0.0639\n",
      "            teddy bear        128         21      0.936      0.381      0.618      0.416\n",
      "            toothbrush        128          5      0.675      0.419      0.728      0.455\n",
      "Speed: 1.3ms preprocess, 36.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Ultralytics YOLOv8.1.15 üöÄ Python-3.11.9 torch-2.2.0+cpu CPU (12th Gen Intel Core(TM) i7-12700H)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\work\\github\\first-project\\main_code\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:05<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.659      0.533      0.616      0.459\n",
      "                person        128        254      0.804      0.669      0.765      0.548\n",
      "               bicycle        128          6      0.619      0.333      0.318      0.277\n",
      "                   car        128         46      0.705      0.217      0.277      0.171\n",
      "            motorcycle        128          5      0.669       0.81      0.938      0.754\n",
      "              airplane        128          6      0.751      0.667      0.846      0.588\n",
      "                   bus        128          7      0.527       0.64      0.657      0.595\n",
      "                 train        128          3      0.539      0.667      0.806      0.698\n",
      "                 truck        128         12      0.868      0.333      0.475      0.264\n",
      "                  boat        128          6      0.358      0.167      0.365      0.206\n",
      "         traffic light        128         14      0.725      0.214      0.206       0.14\n",
      "             stop sign        128          2          1      0.938      0.995      0.703\n",
      "                 bench        128          9       0.78      0.401      0.623      0.387\n",
      "                  bird        128         16      0.917      0.687      0.902      0.539\n",
      "                   cat        128          4      0.862          1      0.995       0.82\n",
      "                   dog        128          9      0.724      0.874      0.851      0.619\n",
      "                 horse        128          2      0.566          1      0.995      0.597\n",
      "              elephant        128         17      0.957      0.824      0.896      0.701\n",
      "                  bear        128          1      0.644          1      0.995      0.895\n",
      "                 zebra        128          4      0.861          1      0.995      0.965\n",
      "               giraffe        128          9      0.804      0.913      0.951      0.752\n",
      "              backpack        128          6      0.581      0.333      0.393      0.248\n",
      "              umbrella        128         18      0.748        0.5      0.685      0.452\n",
      "               handbag        128         19      0.453     0.0477      0.155     0.0884\n",
      "                   tie        128          7      0.829      0.694      0.702      0.492\n",
      "              suitcase        128          4      0.562          1      0.895      0.621\n",
      "               frisbee        128          5      0.607        0.8      0.732      0.639\n",
      "                  skis        128          1      0.456          1      0.497      0.211\n",
      "             snowboard        128          7      0.784      0.714      0.763      0.489\n",
      "           sports ball        128          6      0.734      0.467      0.556      0.314\n",
      "                  kite        128         10      0.815      0.444       0.56      0.174\n",
      "          baseball bat        128          4      0.432       0.25      0.379      0.177\n",
      "        baseball glove        128          7      0.647      0.429      0.429      0.316\n",
      "            skateboard        128          5       0.87        0.6        0.6       0.44\n",
      "         tennis racket        128          7      0.678      0.306      0.447      0.313\n",
      "                bottle        128         18      0.479      0.333      0.383      0.224\n",
      "            wine glass        128         16      0.689      0.375      0.538      0.347\n",
      "                   cup        128         36      0.709      0.278      0.441      0.303\n",
      "                  fork        128          6      0.593      0.167      0.274        0.2\n",
      "                 knife        128         16      0.606      0.562      0.586      0.348\n",
      "                 spoon        128         22      0.828       0.22       0.37      0.202\n",
      "                  bowl        128         28       0.72      0.733      0.662      0.534\n",
      "                banana        128          1          0          0      0.142      0.046\n",
      "              sandwich        128          2      0.365        0.5      0.497      0.497\n",
      "                orange        128          4          1      0.412      0.995      0.669\n",
      "              broccoli        128         11      0.527      0.182      0.274      0.234\n",
      "                carrot        128         24      0.734      0.583      0.663      0.411\n",
      "               hot dog        128          2      0.547          1      0.828      0.828\n",
      "                 pizza        128          5      0.789          1      0.995      0.852\n",
      "                 donut        128         14      0.615          1      0.894      0.814\n",
      "                  cake        128          4      0.611          1      0.995      0.834\n",
      "                 chair        128         35      0.473      0.514      0.427      0.256\n",
      "                 couch        128          6      0.622        0.5       0.73      0.586\n",
      "          potted plant        128         14      0.573      0.571      0.672      0.468\n",
      "                   bed        128          3      0.954      0.667      0.913       0.71\n",
      "          dining table        128         13      0.477      0.462      0.487      0.388\n",
      "                toilet        128          2      0.646        0.5      0.828      0.796\n",
      "                    tv        128          2       0.54        0.5      0.662      0.629\n",
      "                laptop        128          3          1          0      0.481      0.385\n",
      "                 mouse        128          2          1          0     0.0436    0.00436\n",
      "                remote        128          8      0.752        0.5      0.597      0.494\n",
      "            cell phone        128          8          0          0     0.0425     0.0212\n",
      "             microwave        128          3      0.401      0.671       0.83      0.716\n",
      "                  oven        128          5      0.354        0.4      0.378      0.294\n",
      "                  sink        128          6      0.383      0.167      0.247       0.17\n",
      "          refrigerator        128          5      0.603        0.4      0.618      0.483\n",
      "                  book        128         29      0.479      0.103      0.303      0.158\n",
      "                 clock        128          9       0.78      0.789      0.901      0.739\n",
      "                  vase        128          2      0.448          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.199     0.0643\n",
      "            teddy bear        128         21      0.943      0.381      0.617      0.414\n",
      "            toothbrush        128          5      0.692      0.461      0.736      0.479\n",
      "Speed: 0.7ms preprocess, 31.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train22\u001b[0m\n",
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 476k/476k [00:00<00:00, 570kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 e:\\work\\github\\first-project\\main_code\\ultralytics\\ultralytics\\ultralytics\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 176.7ms\n",
      "Speed: 4.0ms preprocess, 176.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Ultralytics YOLOv8.1.15 üöÄ Python-3.11.9 torch-2.2.0+cpu CPU (12th Gen Intel Core(TM) i7-12700H)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.16.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\amir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnx>=1.12.0) (4.23.4)\n",
      "Downloading onnx-1.16.0-cp311-cp311-win_amd64.whl (14.4 MB)\n",
      "   ---------------------------------------- 14.4/14.4 MB 8.2 MB/s eta 0:00:005\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.16.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 17.8s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 18.9s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (20.6s)\n",
      "Results saved to \u001b[1mE:\\work\\github\\first-project\\main_code\\ultralytics\\ultralytics\\ultralytics\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
    "results = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "success = YOLO(\"yolov8n.pt\").export(format=\"onnx\")  # export a model to ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_label(image, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n",
    "  lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n",
    "  p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "  cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "  if label:\n",
    "    tf = max(lw - 1, 1)  # font thickness\n",
    "    w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
    "    outside = p1[1] - h >= 3\n",
    "    p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "    cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "    cv2.putText(image,\n",
    "                label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "                0,\n",
    "                lw / 3,\n",
    "                txt_color,\n",
    "                thickness=tf,\n",
    "                lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bboxes(image, boxes, labels=[], colors=[], score=True, conf=None):\n",
    "  #Define COCO Labels\n",
    "  if labels == []:\n",
    "    labels = {0: u'__background__', 1: u'person', 2: u'bicycle',3: u'car', 4: u'motorcycle', 5: u'airplane', 6: u'bus', 7: u'train', 8: u'truck', 9: u'boat', 10: u'traffic light', 11: u'fire hydrant', 12: u'stop sign', 13: u'parking meter', 14: u'bench', 15: u'bird', 16: u'cat', 17: u'dog', 18: u'horse', 19: u'sheep', 20: u'cow', 21: u'elephant', 22: u'bear', 23: u'zebra', 24: u'giraffe', 25: u'backpack', 26: u'umbrella', 27: u'handbag', 28: u'tie', 29: u'suitcase', 30: u'frisbee', 31: u'skis', 32: u'snowboard', 33: u'sports ball', 34: u'kite', 35: u'baseball bat', 36: u'baseball glove', 37: u'skateboard', 38: u'surfboard', 39: u'tennis racket', 40: u'bottle', 41: u'wine glass', 42: u'cup', 43: u'fork', 44: u'knife', 45: u'spoon', 46: u'bowl', 47: u'banana', 48: u'apple', 49: u'sandwich', 50: u'orange', 51: u'broccoli', 52: u'carrot', 53: u'hot dog', 54: u'pizza', 55: u'donut', 56: u'cake', 57: u'chair', 58: u'couch', 59: u'potted plant', 60: u'bed', 61: u'dining table', 62: u'toilet', 63: u'tv', 64: u'laptop', 65: u'mouse', 66: u'remote', 67: u'keyboard', 68: u'cell phone', 69: u'microwave', 70: u'oven', 71: u'toaster', 72: u'sink', 73: u'refrigerator', 74: u'book', 75: u'clock', 76: u'vase', 77: u'scissors', 78: u'teddy bear', 79: u'hair drier', 80: u'toothbrush'}\n",
    "  #Define colors\n",
    "  if colors == []:\n",
    "    #colors = [(6, 112, 83), (253, 246, 160), (40, 132, 70), (205, 97, 162), (149, 196, 30), (106, 19, 161), (127, 175, 225), (115, 133, 176), (83, 156, 8), (182, 29, 77), (180, 11, 251), (31, 12, 123), (23, 6, 115), (167, 34, 31), (176, 216, 69), (110, 229, 222), (72, 183, 159), (90, 168, 209), (195, 4, 209), (135, 236, 21), (62, 209, 199), (87, 1, 70), (75, 40, 168), (121, 90, 126), (11, 86, 86), (40, 218, 53), (234, 76, 20), (129, 174, 192), (13, 18, 254), (45, 183, 149), (77, 234, 120), (182, 83, 207), (172, 138, 252), (201, 7, 159), (147, 240, 17), (134, 19, 233), (202, 61, 206), (177, 253, 26), (10, 139, 17), (130, 148, 106), (174, 197, 128), (106, 59, 168), (124, 180, 83), (78, 169, 4), (26, 79, 176), (185, 149, 150), (165, 253, 206), (220, 87, 0), (72, 22, 226), (64, 174, 4), (245, 131, 96), (35, 217, 142), (89, 86, 32), (80, 56, 196), (222, 136, 159), (145, 6, 219), (143, 132, 162), (175, 97, 221), (72, 3, 79), (196, 184, 237), (18, 210, 116), (8, 185, 81), (99, 181, 254), (9, 127, 123), (140, 94, 215), (39, 229, 121), (230, 51, 96), (84, 225, 33), (218, 202, 139), (129, 223, 182), (167, 46, 157), (15, 252, 5), (128, 103, 203), (197, 223, 199), (19, 238, 181), (64, 142, 167), (12, 203, 242), (69, 21, 41), (177, 184, 2), (35, 97, 56), (241, 22, 161)]\n",
    "    colors = [(89, 161, 197),(67, 161, 255),(19, 222, 24),(186, 55, 2),(167, 146, 11),(190, 76, 98),(130, 172, 179),(115, 209, 128),(204, 79, 135),(136, 126, 185),(209, 213, 45),(44, 52, 10),(101, 158, 121),(179, 124, 12),(25, 33, 189),(45, 115, 11),(73, 197, 184),(62, 225, 221),(32, 46, 52),(20, 165, 16),(54, 15, 57),(12, 150, 9),(10, 46, 99),(94, 89, 46),(48, 37, 106),(42, 10, 96),(7, 164, 128),(98, 213, 120),(40, 5, 219),(54, 25, 150),(251, 74, 172),(0, 236, 196),(21, 104, 190),(226, 74, 232),(120, 67, 25),(191, 106, 197),(8, 15, 134),(21, 2, 1),(142, 63, 109),(133, 148, 146),(187, 77, 253),(155, 22, 122),(218, 130, 77),(164, 102, 79),(43, 152, 125),(185, 124, 151),(95, 159, 238),(128, 89, 85),(228, 6, 60),(6, 41, 210),(11, 1, 133),(30, 96, 58),(230, 136, 109),(126, 45, 174),(164, 63, 165),(32, 111, 29),(232, 40, 70),(55, 31, 198),(148, 211, 129),(10, 186, 211),(181, 201, 94),(55, 35, 92),(129, 140, 233),(70, 250, 116),(61, 209, 152),(216, 21, 138),(100, 0, 176),(3, 42, 70),(151, 13, 44),(216, 102, 88),(125, 216, 93),(171, 236, 47),(253, 127, 103),(205, 137, 244),(193, 137, 224),(36, 152, 214),(17, 50, 238),(154, 165, 67),(114, 129, 60),(119, 24, 48),(73, 8, 110)]\n",
    "  \n",
    "  #plot each boxes\n",
    "  for box in boxes:\n",
    "    #add score in label if score=True\n",
    "    if score :\n",
    "      label = labels[int(box[-1])+1] + \" \" + str(round(100 * float(box[-2]),1)) + \"%\"\n",
    "    else :\n",
    "      label = labels[int(box[-1])+1]\n",
    "    #filter every box under conf threshold if conf threshold setted\n",
    "    if conf :\n",
    "      if box[-2] > conf:\n",
    "        color = colors[int(box[-1])]\n",
    "        box_label(image, box, label, color)\n",
    "    else:\n",
    "      color = colors[int(box[-1])]\n",
    "      box_label(image, box, label, color)\n",
    "\n",
    "  #show image\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "  except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "  if IN_COLAB:\n",
    "    cv2_imshow(image) #if used in Colab\n",
    "  else :\n",
    "    cv2.imshow(image) #if used in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
